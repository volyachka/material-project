{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import nan as Nan\n",
    "from numpy import inf as inf\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostRegressor, Pool, EShapCalcType, EFeaturesSelectionAlgorithm\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostRegressor, Pool, EShapCalcType, EFeaturesSelectionAlgorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from data_preprocessing import *\n",
    "from sklearn.model_selection import KFold\n",
    "from utils import *\n",
    "from scoring import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [1, 2, 3]\n",
    "\n",
    "with open(\"file.txt\", \"w\") as output:\n",
    "    output.write(str(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"file.txt\", \"r\") as f:\n",
    "    array = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i in range(5):\n",
    "    dfs.append(load_csv(f\"groups_and_oxi_states_5_frames/df_features_with_barrier_step_{i}.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0]['stru_label'].to_list() == dfs[1]['stru_label'].to_list() == dfs[2]['stru_label'].to_list() == dfs[3]['stru_label'].to_list() == dfs[4]['stru_label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/material-project/leave_one_out.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f4e45575f4844442f4844445f3354422f6f6c79616f6c79612f6d6174657269616c2d70726f6a656374222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f687365677075227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f4e45575f4844442f4844445f3354422f6f6c79616f6c79612f6d6174657269616c2d70726f6a6563742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/material-project/leave_one_out.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m preds_without_traj, y \u001b[39m=\u001b[39m test_function_without_trajectories(dfs[\u001b[39m0\u001b[39;49m], number_of_folds \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m, random_state \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f4e45575f4844442f4844445f3354422f6f6c79616f6c79612f6d6174657269616c2d70726f6a656374222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f687365677075227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f4e45575f4844442f4844445f3354422f6f6c79616f6c79612f6d6174657269616c2d70726f6a6563742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/material-project/leave_one_out.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m bootstrap_roc_auc(\u001b[39m1000\u001b[39m, y, preds_without_traj)\n",
      "File \u001b[0;32m/workspaces/material-project/scoring.py:85\u001b[0m, in \u001b[0;36mtest_function_without_trajectories\u001b[0;34m(df, number_of_folds, random_state)\u001b[0m\n\u001b[1;32m     83\u001b[0m kf \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39mnumber_of_folds, random_state\u001b[39m=\u001b[39mrandom_state, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     84\u001b[0m kf\u001b[39m.\u001b[39mget_n_splits(X_scaled)\n\u001b[0;32m---> 85\u001b[0m \u001b[39mfor\u001b[39;00m train_index, test_index \u001b[39min\u001b[39;00m tqdm(kf\u001b[39m.\u001b[39;49msplit(X)):\n\u001b[1;32m     86\u001b[0m     X_tr, X_te, y_tr, y_te \u001b[39m=\u001b[39m (X_scaled[train_index, :], X_scaled[test_index, :], y[train_index], y[test_index])\n\u001b[1;32m     87\u001b[0m     model \u001b[39m=\u001b[39m CatBoostClassifier(eval_metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAUC\u001b[39m\u001b[39m'\u001b[39m, verbose \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "preds_without_traj, y = test_function_without_trajectories(dfs[0], number_of_folds = 3, random_state = 0)\n",
    "bootstrap_roc_auc(1000, y, preds_without_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc score for train: 1.0, for test 0.8777777777777778\n",
      "roc auc score for train: 1.0, for test 0.8814814814814814\n",
      "roc auc score for train: 1.0, for test 0.9666666666666667\n",
      "roc auc score for train: 1.0, for test 0.9370370370370371\n",
      "roc auc score for train: 1.0, for test 0.9962962962962963\n",
      "roc auc score for train: 1.0, for test 0.9184782608695652\n",
      "roc auc score for train: 1.0, for test 0.9755434782608696\n",
      "roc auc score for train: 1.0, for test 0.9429347826086956\n",
      "roc auc score for train: 1.0, for test 0.9320652173913043\n",
      "roc auc score for train: 1.0, for test 0.9510869565217391\n",
      "roc auc score for train: 1.0, for test 0.8095238095238095\n",
      "roc auc score for train: 1.0, for test 0.8235294117647058\n",
      "roc auc score for train: 0.989811320754717, for test 0.8515406162464986\n",
      "roc auc score for train: 0.9984905660377359, for test 0.8403361344537815\n",
      "roc auc score for train: 1.0, for test 0.8207282913165266\n"
     ]
    }
   ],
   "source": [
    "preds_with_traj, preds_without_traj, y = test_function_with_trajectories(dfs, number_of_folds = 3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9136169346361901, 0.026919651239747162)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_roc_auc(1000, y, preds_with_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8352166142789906, 0.040838305791136356)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_roc_auc(1000, y, preds_without_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc score 0.9248120300751879\n",
      "roc auc score 0.9154135338345865\n",
      "roc auc score 0.9379699248120301\n",
      "roc auc score 0.8383458646616541\n",
      "roc auc score 0.8853383458646618\n",
      "roc auc score 0.9022556390977443 for random_split 8334788\n",
      "roc auc score 0.9133064516129032\n",
      "roc auc score 0.8326612903225806\n",
      "roc auc score 0.8366935483870968\n",
      "roc auc score 0.9092741935483871\n",
      "roc auc score 0.8588709677419355\n",
      "roc auc score 0.8850806451612904 for random_split 9151291\n",
      "roc auc score 0.8113553113553112\n",
      "roc auc score 0.912087912087912\n",
      "roc auc score 0.8406593406593407\n",
      "roc auc score 0.8498168498168498\n",
      "roc auc score 0.8901098901098901\n",
      "roc auc score 0.8736263736263736 for random_split 4517925\n",
      "roc auc score 0.8509803921568627\n",
      "roc auc score 0.8725490196078433\n",
      "roc auc score 0.888235294117647\n",
      "roc auc score 0.8686274509803922\n",
      "roc auc score 0.9235294117647059\n",
      "roc auc score 0.903921568627451 for random_split 5765657\n",
      "roc auc score 0.9745098039215686\n",
      "roc auc score 0.9431372549019609\n",
      "roc auc score 0.9372549019607843\n",
      "roc auc score 0.9431372549019608\n",
      "roc auc score 0.9549019607843138\n",
      "roc auc score 0.9627450980392157 for random_split 1797675\n",
      "mean roc auc 0.905525864910415\n"
     ]
    }
   ],
   "source": [
    "splits = [8334788, 9151291, 4517925, 5765657, 1797675]\n",
    "roc_auc = []\n",
    "for random_split in splits:\n",
    "    assembled_pred = np.zeros(47)\n",
    "    for i, df in enumerate(dfs):\n",
    "        X, y = (df.drop(['is_good', 'stru_label', 'stru_id'], axis=1), df['is_good'])\n",
    "        X = X.to_numpy()\n",
    "        y = y.astype(int)\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        if i == 0:\n",
    "            X_tr, X_te, y_tr, y_te = train_test_split(X_scaled, y, test_size=0.4, random_state=random_split)\n",
    "        else:\n",
    "            X_tr, _, y_tr, _ = train_test_split(X_scaled, y, test_size=0.4, random_state=random_split)\n",
    "        model = CatBoostClassifier(eval_metric='AUC', verbose = False)\n",
    "        feature_names = ['F{}'.format(i) for i in range(np.array(X_tr).shape[1])]\n",
    "        test_pool = Pool(np.array(X_te), y_te, feature_names=feature_names)\n",
    "        summary = model.select_features(\n",
    "        X = X_tr,\n",
    "        y=y_tr,\n",
    "        eval_set=test_pool,\n",
    "        features_for_select= np.arange(len(X_tr[0])),\n",
    "        num_features_to_select=50,\n",
    "        steps=6,\n",
    "        algorithm=EFeaturesSelectionAlgorithm.RecursiveByShapValues,\n",
    "        shap_calc_type=EShapCalcType.Regular,\n",
    "        train_final_model=True,\n",
    "        logging_level='Silent',\n",
    "        plot=False)\n",
    "        y_pred = model.predict_proba(X_te)[:, 1]\n",
    "        assembled_pred += y_pred\n",
    "        print(f\"roc auc score {roc_auc_score(y_te, y_pred)}\")\n",
    "        indexes = np.argsort(model.predict_proba(X_te)[:, 1])\n",
    "    assembled_pred /= len(dfs)\n",
    "    roc_auc.append(roc_auc_score(y_te, assembled_pred))\n",
    "    print(f\"roc auc score {roc_auc[-1]} for random_split {random_split}\")\n",
    "print(f\"mean roc auc {np.mean(roc_auc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc score 0.8825757575757576\n",
      "roc auc score 0.9015151515151515\n",
      "roc auc score 0.9166666666666666\n",
      "roc auc score 0.9431818181818181\n",
      "roc auc score 0.9071969696969697\n",
      "roc auc score 0.9318181818181819 for random_split 8334788\n",
      "roc auc score 0.8038461538461539\n",
      "roc auc score 0.823076923076923\n",
      "roc auc score 0.9\n",
      "roc auc score 0.8576923076923078\n",
      "roc auc score 0.8730769230769231\n",
      "roc auc score 0.8692307692307693 for random_split 9151291\n",
      "roc auc score 0.9412878787878788\n",
      "roc auc score 0.928030303030303\n",
      "roc auc score 0.8674242424242424\n",
      "roc auc score 0.8920454545454546\n",
      "roc auc score 0.8920454545454546\n",
      "roc auc score 0.9261363636363635 for random_split 4517925\n",
      "roc auc score 0.9288461538461539\n",
      "roc auc score 0.6673076923076924\n",
      "roc auc score 0.8173076923076923\n",
      "roc auc score 0.8769230769230769\n",
      "roc auc score 0.8884615384615385\n",
      "roc auc score 0.823076923076923 for random_split 5765657\n",
      "roc auc score 0.9142300194931774\n",
      "roc auc score 0.949317738791423\n",
      "roc auc score 0.9083820662768031\n",
      "roc auc score 0.9512670565302144\n",
      "roc auc score 0.935672514619883\n",
      "roc auc score 0.9473684210526315 for random_split 1797675\n",
      "mean roc auc 0.8995261317629739\n"
     ]
    }
   ],
   "source": [
    "splits = [8334788, 9151291, 4517925, 5765657, 1797675]\n",
    "roc_auc = []\n",
    "for random_split in splits:\n",
    "    assembled_pred = np.zeros(46)\n",
    "    for df in dfs:\n",
    "        X, y = (df.drop(['is_good', 'stru_label'], axis=1), df['is_good'])\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        y = y.astype(int)\n",
    "        X_tr, X_te, y_tr, y_te = train_test_split(X_scaled, y, test_size=0.4, random_state=random_split)\n",
    "        model = CatBoostClassifier(eval_metric='AUC', verbose = False)\n",
    "        feature_names = ['F{}'.format(i) for i in range(np.array(X_tr).shape[1])]\n",
    "        test_pool = Pool(np.array(X_te), y_te, feature_names=feature_names)\n",
    "        summary = model.select_features(\n",
    "        X = X_tr,\n",
    "        y=y_tr,\n",
    "        eval_set=test_pool,\n",
    "        features_for_select= np.arange(len(X_tr[0])),\n",
    "        num_features_to_select=20,\n",
    "        steps=6,\n",
    "        algorithm=EFeaturesSelectionAlgorithm.RecursiveByShapValues,\n",
    "        shap_calc_type=EShapCalcType.Regular,\n",
    "        train_final_model=True,\n",
    "        logging_level='Silent',\n",
    "        plot=False)\n",
    "        y_pred = model.predict_proba(X_te)[:, 1]\n",
    "        assembled_pred += y_pred\n",
    "        print(f\"roc auc score {roc_auc_score(y_te, y_pred)}\")\n",
    "        indexes = np.argsort(model.predict_proba(X_te)[:, 1])\n",
    "    assembled_pred /= len(dfs)\n",
    "    roc_auc.append(roc_auc_score(y_te, assembled_pred))\n",
    "    print(f\"roc auc score {roc_auc[-1]} for random_split {random_split}\")\n",
    "print(f\"mean roc auc {np.mean(roc_auc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc score 0.9034090909090908\n",
      "roc auc score 0.8939393939393939\n",
      "roc auc score 0.9034090909090908\n",
      "roc auc score 0.9109848484848486\n",
      "roc auc score 0.8996212121212122\n",
      "roc auc score 0.9242424242424242 for random_split 8334788\n",
      "roc auc score 0.8076923076923077\n",
      "roc auc score 0.8153846153846154\n",
      "roc auc score 0.8461538461538461\n",
      "roc auc score 0.8576923076923078\n",
      "roc auc score 0.6749999999999999\n",
      "roc auc score 0.8403846153846154 for random_split 9151291\n",
      "roc auc score 0.8570075757575758\n",
      "roc auc score 0.9166666666666666\n",
      "roc auc score 0.7443181818181818\n",
      "roc auc score 0.9034090909090909\n",
      "roc auc score 0.8257575757575757\n",
      "roc auc score 0.9090909090909092 for random_split 4517925\n",
      "roc auc score 0.8730769230769231\n",
      "roc auc score 0.8865384615384615\n",
      "roc auc score 0.675\n",
      "roc auc score 0.6557692307692308\n",
      "roc auc score 0.8807692307692307\n",
      "roc auc score 0.8365384615384616 for random_split 5765657\n",
      "roc auc score 0.8304093567251463\n",
      "roc auc score 0.9512670565302143\n",
      "roc auc score 0.9473684210526315\n",
      "roc auc score 0.9454191033138402\n",
      "roc auc score 0.9200779727095516\n",
      "roc auc score 0.9473684210526315 for random_split 1797675\n",
      "mean roc auc 0.8915249662618084\n"
     ]
    }
   ],
   "source": [
    "splits = [8334788, 9151291, 4517925, 5765657, 1797675]\n",
    "roc_auc = []\n",
    "for random_split in splits:\n",
    "    assembled_pred = np.zeros(46)\n",
    "    for df in dfs:\n",
    "        grand_X = list()\n",
    "        grand_y = list()\n",
    "        X, y = (df.drop(['is_good', 'stru_label'], axis=1), df['is_good'])\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        grand_X.append(X_scaled)\n",
    "        y = y.astype(int)\n",
    "        grand_y.append(y)\n",
    "        X_tr = list()\n",
    "        y_tr = list()\n",
    "        X_te = list()\n",
    "        y_te = list()\n",
    "        for X_scaled, y in zip(grand_X, grand_y):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.4, random_state=random_split)\n",
    "            X_tr.extend(X_train)\n",
    "            X_te.extend(X_test)\n",
    "            y_tr.extend(y_train)\n",
    "            y_te.extend(y_test)\n",
    "        model = CatBoostClassifier(eval_metric='AUC', verbose = False)\n",
    "        feature_names = ['F{}'.format(i) for i in range(np.array(X_tr).shape[1])]\n",
    "        test_pool = Pool(np.array(X_te), y_te, feature_names=feature_names)\n",
    "        summary = model.select_features(\n",
    "        X = X_tr,\n",
    "        y=y_tr,\n",
    "        eval_set=test_pool,\n",
    "        features_for_select= np.arange(len(X_tr[0])),\n",
    "        num_features_to_select=50,\n",
    "        steps=3,\n",
    "        algorithm=EFeaturesSelectionAlgorithm.RecursiveByShapValues,\n",
    "        shap_calc_type=EShapCalcType.Regular,\n",
    "        train_final_model=True,\n",
    "        logging_level='Silent',\n",
    "        plot=False)\n",
    "        y_pred = model.predict_proba(X_te)[:, 1]\n",
    "        assembled_pred += y_pred\n",
    "        print(f\"roc auc score {roc_auc_score(y_te, y_pred)}\")\n",
    "        indexes = np.argsort(model.predict_proba(X_te)[:, 1])\n",
    "    assembled_pred /= len(dfs)\n",
    "    roc_auc.append(roc_auc_score(y_te, assembled_pred))\n",
    "    print(f\"roc auc score {roc_auc[-1]} for random_split {random_split}\")\n",
    "print(f\"mean roc auc {np.mean(roc_auc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_preprocessing(dfs, include_trajectories = False):\n",
    "    grand_X = list()\n",
    "    grand_y = list()\n",
    "    for df in dfs:\n",
    "        scaler = StandardScaler()\n",
    "        X, y = (df.drop(['is_good', 'stru_label'], axis=1), df['is_good'])\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        grand_X.append(X_scaled)\n",
    "        y = y.astype(int)\n",
    "        grand_y.append(y)\n",
    "        if not include_trajectories:\n",
    "            break\n",
    "    return grand_X, grand_y\n",
    "\n",
    "def get_train_test(grand_X, grand_y, random_split):\n",
    "    X_tr = list()\n",
    "    y_tr = list()\n",
    "    X_te = list()\n",
    "    y_te = list()\n",
    "    for X_scaled, y in zip(grand_X, grand_y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.4, random_state=random_split)\n",
    "        X_tr.extend(X_train)\n",
    "        X_te.extend(X_test)\n",
    "        y_tr.extend(y_train)\n",
    "        y_te.extend(y_test)\n",
    "    X_tr = np.array(X_tr)\n",
    "    X_te = np.array(X_te)\n",
    "    return X_tr, X_te, y_tr, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameters_of_select_features(num_features, steps):\n",
    "    grand_X, grand_y = feature_preprocessing(dfs, True)\n",
    "\n",
    "    roc_auc = []\n",
    "    splits = [8334788, 9151291, 4517925, 5765657, 1797675]\n",
    "\n",
    "\n",
    "    for random_split in splits:\n",
    "        assembled_pred = np.zeros(46)\n",
    "        for X_scaled, y in zip(grand_X, grand_y):\n",
    "            X_te = list()\n",
    "            y_te = list()\n",
    "            X_tr, X_te, y_tr, y_te = train_test_split(X_scaled, y, test_size=0.4, random_state=random_split)\n",
    "            model = CatBoostClassifier(eval_metric='AUC', verbose = False)\n",
    "            feature_names = ['F{}'.format(i) for i in range(np.array(X_tr).shape[1])]\n",
    "            test_pool = Pool(np.array(X_te), y_te, feature_names=feature_names)\n",
    "            summary = model.select_features(\n",
    "            X = X_tr,\n",
    "            y=y_tr,\n",
    "            eval_set=test_pool,\n",
    "            features_for_select= np.arange(len(X_tr[0])),\n",
    "            num_features_to_select=num_features,\n",
    "            steps=steps,\n",
    "            algorithm=EFeaturesSelectionAlgorithm.RecursiveByShapValues,\n",
    "            shap_calc_type=EShapCalcType.Regular,\n",
    "            train_final_model=True,\n",
    "            logging_level='Silent',\n",
    "            plot=False)\n",
    "            y_pred = model.predict_proba(X_te)[:, 1]\n",
    "            print(roc_auc_score(y_te, y_pred), random_split)\n",
    "            assembled_pred += y_pred\n",
    "        assembled_pred /= len(dfs)\n",
    "        print(f\"roc auc score {roc_auc_score(y_te, assembled_pred)} for random split {random_split}\")\n",
    "        roc_auc.append(roc_auc_score(y_te, assembled_pred))\n",
    "    print(f\"mean roc auc score {np.mean(roc_auc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_features_to_select=80, steps=6 for all trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "667 - 577 = 90"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
